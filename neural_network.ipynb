{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c90b0a-6e22-47c0-b303-6ea10ef483e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Credentials to connect to the database\n",
    "username = \"username\"\n",
    "password = \"DB_password\"\n",
    "hostname = \"DB_host\"\n",
    "dbname = \"DB_name\"\n",
    "\n",
    "# Split the training and validation datasets using the valid_fraction\n",
    "def get_data_splits(dataframe, valid_fraction=0.2):\n",
    "    valid_size = int(len(dataframe) * valid_fraction)\n",
    "    valid_size = max(valid_size, 1)\n",
    "    train = dataframe[:-valid_size]\n",
    "    valid = dataframe[-valid_size:]\n",
    "    return train, valid\n",
    "\n",
    "def neural_network(nodes, input_length):\n",
    "    \"\"\"\n",
    "    Create the neural network\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes, input_dim=input_length, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='relu'))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "# Create training and validation datasets\n",
    "def create_train_valid_set():\n",
    "    # Connect to the database of the e-shop\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://{username}:{password}@{hostname}/{dbname}\")\n",
    "\n",
    "    nn_data = pd.read_sql_table(\"nn_data\", engine)\n",
    "    nn_data = nn_data.drop(columns=[\"week\", \"product_cost\", \"product_max_bound\"])\n",
    "\n",
    "    train = pd.DataFrame(columns=nn_data.columns)\n",
    "    valid = pd.DataFrame(columns=nn_data.columns)\n",
    "\n",
    "    for product in nn_data.product_id.unique():\n",
    "        dataframe = nn_data[nn_data.product_id == product]\n",
    "        std = dataframe.iloc[:, -1].std()\n",
    "        mean = dataframe.iloc[:, -1].mean()\n",
    "        if std <= mean:\n",
    "            temp_train, temp_valid = get_data_splits(dataframe)\n",
    "            train = pd.concat([train, temp_train], ignore_index=True)\n",
    "            valid = pd.concat([valid, temp_valid], ignore_index=True)\n",
    "\n",
    "    X_train = train.iloc[:, :-1]\n",
    "    y_train = train.iloc[:, -1]\n",
    "    X_valid = valid.iloc[:, :-1]\n",
    "    y_valid = valid.iloc[:, -1]\n",
    "\n",
    "    product_encoder = LabelEncoder()\n",
    "    X_train[\"product_id\"] = product_encoder.fit_transform(X_train[\"product_id\"].astype(str))\n",
    "    X_valid[\"product_id\"] = product_encoder.transform(X_valid[\"product_id\"].astype(str))\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "# Test the neural network and its performance\n",
    "def nn_testing():\n",
    "    X_train, X_valid, y_train, y_valid = create_train_valid_set()\n",
    "\n",
    "    model = neural_network(23, X_train.shape[1])\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=100, batch_size=256,\n",
    "                        validation_data=(X_valid, y_valid),\n",
    "                        verbose=0)\n",
    "\n",
    "    loss_values = history.history['loss']\n",
    "    val_loss_values = history.history['val_loss']\n",
    "\n",
    "    plt.plot(loss_values, label='Training Loss')\n",
    "    plt.plot(val_loss_values, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    y_train_pred = np.round(model.predict(X_train))\n",
    "    y_valid_pred = np.round(model.predict(X_valid))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    valid_mae = mean_absolute_error(y_valid, y_valid_pred)\n",
    "\n",
    "    print(f\"The R2 score on the Train set is: {r2_score(y_train, y_train_pred):.3f}\")\n",
    "    print(f\"The R2 score on the Valid set is: {r2_score(y_valid, y_valid_pred):.3f}\")\n",
    "    print(f\"The MAE on the Train set is: {train_mae:.3f}\")\n",
    "    print(f\"The mean of the Train set is: {y_train.mean():.3f}\")\n",
    "    print(f\"The percentage of MAE on Train set is: {(train_mae / y_train.mean()) * 100:.2f}%\")\n",
    "    print(f\"The MAE on the Valid set is: {valid_mae:.3f}\")\n",
    "    print(f\"The mean of the Valid set is: {y_valid.mean():.3f}\")\n",
    "    print(f\"The percentage of MAE on Valid set is: {(valid_mae / y_valid.mean()) * 100:.2f}%\")\n",
    "\n",
    "# Final training of the neural network\n",
    "def nn_final_training():\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://{username}:{password}@{hostname}/{dbname}\")\n",
    "\n",
    "    nn_data = pd.read_sql_table(\"nn_data\", engine)\n",
    "    nn_data = nn_data.drop(columns=[\"week\", \"product_cost\", \"product_max_bound\"])\n",
    "\n",
    "    X_train = nn_data.iloc[:, :-1]\n",
    "    y_train = nn_data.iloc[:, -1]\n",
    "\n",
    "    product_encoder = LabelEncoder()\n",
    "    X_train[\"product_id\"] = product_encoder.fit_transform(X_train[\"product_id\"].astype(str))\n",
    "\n",
    "    model = neural_network(23, X_train.shape[1])\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=0)\n",
    "    model.save(\"final_model.h5\")\n",
    "    return product_encoder\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nn_testing()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
